--- a/feeds/luci/applications/luci-app-firewall/htdocs/luci-static/resources/view/firewall/zones.js
+++ b/feeds/luci/applications/luci-app-firewall/htdocs/luci-static/resources/view/firewall/zones.js
@@ -164,8 +164,7 @@
 		p[1].default = fwDefaults.getOutput();
 		p[2].default = fwDefaults.getForward();
 
-		o = s.taboption('general', form.Flag, 'masq', _('IPv4 Masquerading'),
-			_('Enable network address and port translation IPv4 (NAT4 or NAPT4) for outbound traffic on this zone. This is typically enabled on the <em>wan</em> zone.'));
+		o = s.taboption('general', form.Flag, 'masq', _('IPv4 Masquerading'));
 		o.editable = true;
 		o.tooltip = function(section_id) {
 			var family = uci.get('firewall', section_id, 'family')

--- a/feeds/luci/applications/luci-app-ddns/root/usr/share/rpcd/acl.d/luci-app-ddns.json
+++ b/feeds/luci/applications/luci-app-ddns/root/usr/share/rpcd/acl.d/luci-app-ddns.json
@@ -3,7 +3,7 @@
 		"description": "Grant access to ddns procedures",
 		"read": {
 			"ubus": {
-				"luci.ddns": [ "get_services_status", "get_ddns_state", "get_env", "get_services_log" ],
+				"luci.ddns": [ "get_services_status", "get_ddns_state", "get_env", "get_services_log", "reload_ddns_rule", "stop_ddns_rule" ],
 				"luci": [ "setInitAction" ]
 			},
 			"file": {

--- a/feeds/luci/applications/luci-app-ksmbd/root/usr/share/luci/menu.d/luci-app-ksmbd.json
+++ b/feeds/luci/applications/luci-app-ksmbd/root/usr/share/luci/menu.d/luci-app-ksmbd.json
@@ -1,6 +1,7 @@
 {
-	"admin/services/ksmbd": {
+	"admin/nas/ksmbd": {
 		"title": "Network Shares",
+		"order": 2,
 		"action": {
 			"type": "view",
 			"path": "ksmbd"

--- a/feeds/luci/modules/luci-base/root/etc/config/luci
+++ b/feeds/luci/modules/luci-base/root/etc/config/luci
@@ -1,5 +1,5 @@
 config core main
-	option lang auto
+	option lang zh_cn
 	option mediaurlbase /luci-static/bootstrap
 	option resourcebase /luci-static/resources
 	option ubuspath /ubus/

--- a/feeds/packages/net/miniupnpd/files/miniupnpd.init
+++ b/feeds/packages/net/miniupnpd/files/miniupnpd.init
@@ -63,6 +63,7 @@
 	local use_stun stun_host stun_port uuid notify_interval presentation_url
 	local upnp_lease_file clean_ruleset_threshold clean_ruleset_interval
 	local ipv6_disable
+	local force_forwarding
 
 	local enabled
 	config_get_bool enabled config enabled 1
@@ -90,6 +91,7 @@
 	config_get clean_ruleset_threshold config clean_ruleset_threshold
 	config_get clean_ruleset_interval config clean_ruleset_interval
 	config_get ipv6_disable config ipv6_disable 0
+	config_get force_forwarding config force_forwarding 0
 
 	local conf ifname ifname6
 
@@ -142,6 +144,7 @@
 		upnpd_write_bool igdv1 0 force_igd_desc_v1
 		upnpd_write_bool use_stun 0 ext_perform_stun
 		upnpd_write_bool ipv6_disable $ipv6_disable
+		upnpd_write_bool force_forwarding $force_forwarding
 
 		[ "$use_stun" -eq 0 ] || {
 			[ -n "$stun_host" ] && echo "ext_stun_host=$stun_host"

--- a/feeds/packages/net/kcptun/Makefile
+++ b/feeds/packages/net/kcptun/Makefile
@@ -50,7 +33,6 @@
     SUBMENU:=Web Servers/Proxies
     TITLE:=KCP-based Secure Tunnel $(1)
     URL:=https://github.com/xtaci/kcptun
-    DEPENDS:=+kcptun-config
   endef
 
   define Package/kcptun-$(1)/description
@@ -66,7 +48,6 @@
   endef
 endef
 
-$(eval $(call BuildPackage,kcptun-config))
 KCPTUN_COMPONENTS:=server client
 $(foreach component,$(KCPTUN_COMPONENTS), \
   $(eval $(call Package/kcptun/Default,$(component))) \

--- a/feeds/packages/net/ksmbd-tools/files/ksmbd.init
+++ b/feeds/packages/net/ksmbd-tools/files/ksmbd.init
@@ -197,19 +197,20 @@
 {
 	logger -p daemon.notice -t 'ksmbd' "Stopping Ksmbd userspace service."
 	killall ksmbd.mountd > /dev/null 2>&1
-	
+
 	[ -e /sys/module/ksmbd ] && rmmod ksmbd > /dev/null 2>&1
 	# kill server if we cant rmmod
 	[ -e /sys/module/ksmbd ] && kill_server
 	# next try
 	[ -e /sys/module/ksmbd ] && rmmod ksmbd > /dev/null 2>&1
-	
+
 	if [ -e /sys/module/ksmbd ]; then
 		logger -p daemon.error -t 'ksmbd' "module still loaded after kill_server?"
 	fi
 	[ -f /tmp/ksmbd.lock ] && rm /tmp/ksmbd.lock
 }
 
-# reload_service() {
-	# restart "$@"
-# }
+boot(){
+	sleep 5
+	start
+}

--- /dev/null
+++ b/feeds/packages/net/sqm-scripts/patches/001-zh-cn.patch
@@ -0,0 +1,42 @@
+--- a/src/layer_cake.qos.help
++++ b/src/layer_cake.qos.help
+@@ -1,4 +1,4 @@
+-This uses the cake qdisc as a replacement for both htb as shaper and fq_codel as leaf qdisc.
+-This exercises cake's diffserv profile(s) as different "layers" of priority.
+-This script requires that cake is selected as qdisc, and forces its usage.
+-See: http://www.bufferbloat.net/projects/codel/wiki/Cake for more information
++这个cake列队规则使用HTB作为过滤器，使用fq_codel作为叶列队规则。
++这个cake规则将不同的文件分为不同的“层次”优先级。
++该脚本需要将该cake选为列队规则。
++请参阅：http://www.bufferbloat.net/projects/codel/wiki/Cake获取更多信息
+
+--- a/src/piece_of_cake.qos.help
++++ b/src/piece_of_cake.qos.help
+@@ -1,4 +1,4 @@
+-This just uses the cake qdisc as a replacement for both htb as shaper and fq_codel as leaf qdisc.
+-It just does not come any simpler than this, in other words it truely is a "piece of cake".
+-This script requires that cake is selected as qdisc, and forces its usage.
+-See: http://www.bufferbloat.net/projects/codel/wiki/Cake for more information
++这个cake列队规则使用HTB作为过滤器，使用fq_codel作为叶列队规则。
++它不会比这更简单，换句话说，它真的是“小菜一碟”。
++该脚本需要将cake选为列队规则。
++请参阅：http://www.bufferbloat.net/projects/codel/wiki/Cake获取更多信息
+
+--- a/src/simple.qos.help
++++ b/src/simple.qos.help
+@@ -1 +1 @@
+-BW-limited three-tier prioritisation scheme with your qdisc on each queue. (default)
++使用fq_codel列队规则在每个列队上进行三层优先级的带宽控制。（默认）
+
+--- a/src/simplest.qos.help
++++ b/src/simplest.qos.help
+@@ -1 +1 @@
+-Simplest possible configuration: HTB rate limiter with your qdisc attached.
++最简单的配置：使用带有HTB过滤器的列队规则来进行速率限制。
+
+--- a/src/simplest_tbf.qos.help
++++ b/src/simplest_tbf.qos.help
+@@ -1,2 +1 @@
+-Simplest possible configuration (TBF): TBF rate limiter with your qdisc attached.
+-TBF may give better performance than HTB on some architectures.
++最简单的配置（TBF）：使用带有TBF过滤器的列队规则来进行速率限制。在某些架构上，TBF可能会比HTB提供更好的性能。

--- /dev/null
+++ b/feeds/luci/modules/luci-mod-status/htdocs/luci-static/resources/view/status/include/19_cpu.js 
@@ -0,0 +1,45 @@
+'use strict';
+'require rpc';
+
+var callCPUFreeInfo = rpc.declare({
+	object: 'luci',
+	method: 'getCPUUsage'
+});
+
+function progressbar(value, max) {
+	var vn = parseInt(value) || 0,
+	    mn = parseInt(max) || 100,
+	    pc = Math.floor((100 / mn) * vn);
+
+	return E('div', {
+		'class': 'cbi-progressbar',
+		'title': '%s%% / %s%%'.format(vn, mn, pc)
+	}, E('div', { 'style': 'width:%.2f%%'.format(pc) }));
+}
+
+return L.Class.extend({
+	title: _('CPU'),
+
+	load: function() {
+		return L.resolveDefault(callCPUFreeInfo(), {});
+	},
+
+	render: function(info) {
+		var fields = [
+			_('Used'), (info.cpuusage) ? info.cpuusage : 0, 100
+		];
+
+		var table = E('div', { 'class': 'table cpu' });
+
+		for (var i = 0; i < fields.length; i += 3) {
+			table.appendChild(E('div', { 'class': 'tr' }, [
+				E('div', { 'class': 'td left', 'width': '33%' }, [ fields[i] ]),
+				E('div', { 'class': 'td left' }, [
+					(fields[i + 1] != null) ? progressbar(fields[i + 1], fields[i + 2], true) : '?'
+				])
+			]));
+		}
+
+		return table;
+	}
+});

--- /dev/null
+++ b/target/linux/generic/hack-6.12/952-add-net-conntrack-events-support-multiple-registrant.patch
@@ -0,0 +1,356 @@
+--- a/include/net/netfilter/nf_conntrack_ecache.h
++++ b/include/net/netfilter/nf_conntrack_ecache.h
+@@ -65,9 +65,14 @@ struct nf_ct_event_notifier {
+ 	int (*exp_event)(unsigned int events, const struct nf_exp_event *item);
+ };
+ 
+-void nf_conntrack_register_notifier(struct net *net,
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++extern int nf_conntrack_register_notifier(struct net *net, struct notifier_block *nb);
++extern int nf_conntrack_unregister_notifier(struct net *net, struct notifier_block *nb);
++#else
++int nf_conntrack_register_notifier(struct net *net,
+ 				   const struct nf_ct_event_notifier *nb);
+ void nf_conntrack_unregister_notifier(struct net *net);
++#endif
+ 
+ void nf_ct_deliver_cached_events(struct nf_conn *ct);
+ int nf_conntrack_eventmask_report(unsigned int eventmask, struct nf_conn *ct,
+@@ -98,11 +103,13 @@ static inline void
+ nf_conntrack_event_cache(enum ip_conntrack_events event, struct nf_conn *ct)
+ {
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
+-	struct net *net = nf_ct_net(ct);
+ 	struct nf_conntrack_ecache *e;
++#ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	struct net *net = nf_ct_net(ct);
+ 
+ 	if (!rcu_access_pointer(net->ct.nf_conntrack_event_cb))
+ 		return;
++#endif
+ 
+ 	e = nf_ct_ecache_find(ct);
+ 	if (e == NULL)
+@@ -117,20 +124,34 @@ nf_conntrack_event_report(enum ip_conntr
+ 			  u32 portid, int report)
+ {
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
+-	if (nf_ct_ecache_exist(ct))
+-		return nf_conntrack_eventmask_report(1 << event, ct, portid, report);
++#ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	const struct net *net = nf_ct_net(ct);
++
++	if (!rcu_access_pointer(net->ct.nf_conntrack_event_cb))
++		return 0;
+ #endif
++
++	return nf_conntrack_eventmask_report(1 << event, ct, portid, report);
++#else
+ 	return 0;
++#endif
+ }
+ 
+ static inline int
+ nf_conntrack_event(enum ip_conntrack_events event, struct nf_conn *ct)
+ {
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
+-	if (nf_ct_ecache_exist(ct))
+-		return nf_conntrack_eventmask_report(1 << event, ct, 0, 0);
++#ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	const struct net *net = nf_ct_net(ct);
++
++	if (!rcu_access_pointer(net->ct.nf_conntrack_event_cb))
++		return 0;
+ #endif
++
++	return nf_conntrack_eventmask_report(1 << event, ct, 0, 0);
++#else
+ 	return 0;
++#endif
+ }
+ 
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
+--- a/include/net/netns/conntrack.h
++++ b/include/net/netns/conntrack.h
+@@ -105,6 +105,9 @@ struct netns_ct {
+ 	u8			sysctl_checksum;
+ 
+ 	struct ip_conntrack_stat __percpu *stat;
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	struct atomic_notifier_head nf_conntrack_chain;
++#endif
+ 	struct nf_ct_event_notifier __rcu *nf_conntrack_event_cb;
+ 	struct nf_ip_net	nf_ct_proto;
+ #if defined(CONFIG_NF_CONNTRACK_LABELS)
+--- a/net/netfilter/Kconfig
++++ b/net/netfilter/Kconfig
+@@ -161,6 +161,14 @@ config NF_CONNTRACK_EVENTS
+ 
+ 	  If unsure, say `N'.
+ 
++config NF_CONNTRACK_CHAIN_EVENTS
++	bool "Register multiple callbacks to ct events"
++	depends on NF_CONNTRACK_EVENTS
++	help
++	  Support multiple registrations.
++
++	  If unsure, say `N'.
++
+ config NF_CONNTRACK_TIMEOUT
+ 	bool  'Connection tracking timeout'
+ 	depends on NETFILTER_ADVANCED
+--- a/net/netfilter/nf_conntrack_core.c
++++ b/net/netfilter/nf_conntrack_core.c
+@@ -2809,6 +2809,10 @@ int nf_conntrack_init_net(struct net *ne
+ 	nf_conntrack_ecache_pernet_init(net);
+ 	nf_conntrack_proto_pernet_init(net);
+ 
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	ATOMIC_INIT_NOTIFIER_HEAD(&net->ct.nf_conntrack_chain);
++#endif
++
+ 	return 0;
+ 
+ err_expect:
+--- a/net/netfilter/nf_conntrack_ecache.c
++++ b/net/netfilter/nf_conntrack_ecache.c
+@@ -17,6 +17,9 @@
+ #include <linux/stddef.h>
+ #include <linux/err.h>
+ #include <linux/kernel.h>
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++#include <linux/notifier.h>
++#endif
+ #include <linux/netdevice.h>
+ #include <linux/slab.h>
+ #include <linux/export.h>
+@@ -123,7 +126,7 @@ static void ecache_work(struct work_stru
+ 	if (delay >= 0)
+ 		schedule_delayed_work(&cnet->ecache.dwork, delay);
+ }
+-
++#ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+ static int __nf_conntrack_eventmask_report(struct nf_conntrack_ecache *e,
+ 					   const u32 events,
+ 					   const u32 missed,
+@@ -161,7 +164,36 @@ static int __nf_conntrack_eventmask_repo
+ 
+ 	return ret;
+ }
++#endif 
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++int nf_conntrack_eventmask_report(unsigned int eventmask, struct nf_conn *ct,
++				  u32 portid, int report)
++{
++	struct nf_conntrack_ecache *e;
++	struct net *net = nf_ct_net(ct);
++
++	e = nf_ct_ecache_find(ct);
++	if (e == NULL)
++		return 0;
++
++	if (nf_ct_is_confirmed(ct)) {
++		struct nf_ct_event item = {
++			.ct = ct,
++			.portid	= e->portid ? e->portid : portid,
++			.report = report
++		};
++		/* This is a resent of a destroy event? If so, skip missed */
++		unsigned long missed = e->portid ? 0 : e->missed;
++
++		if (!((eventmask | missed) & e->ctmask))
++			return 0;
++
++		atomic_notifier_call_chain(&net->ct.nf_conntrack_chain, eventmask | missed, &item);
++	}
+ 
++	return 0;
++}
++#else
+ int nf_conntrack_eventmask_report(unsigned int events, struct nf_conn *ct,
+ 				  u32 portid, int report)
+ {
+@@ -197,10 +229,52 @@ int nf_conntrack_eventmask_report(unsign
+ 
+ 	return ret;
+ }
++#endif
+ EXPORT_SYMBOL_GPL(nf_conntrack_eventmask_report);
+ 
+ /* deliver cached events and clear cache entry - must be called with locally
+  * disabled softirqs */
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++void nf_ct_deliver_cached_events(struct nf_conn *ct)
++{
++	unsigned long events, missed;
++	struct nf_conntrack_ecache *e;
++	struct nf_ct_event item;
++	struct net *net = nf_ct_net(ct);
++
++	e = nf_ct_ecache_find(ct);
++	if (e == NULL)
++		return;
++
++	events = xchg(&e->cache, 0);
++
++	if (!nf_ct_is_confirmed(ct) || nf_ct_is_dying(ct) || !events)
++		return;
++
++	/* We make a copy of the missed event cache without taking
++	 * the lock, thus we may send missed events twice. However,
++	 * this does not harm and it happens very rarely. */
++	missed = e->missed;
++
++	if (!((events | missed) & e->ctmask))
++		return;
++
++	item.ct = ct;
++	item.portid = 0;
++	item.report = 0;
++
++	atomic_notifier_call_chain(&net->ct.nf_conntrack_chain,
++			events | missed,
++			&item);
++
++	if (likely(!missed))
++		return;
++
++	spin_lock_bh(&ct->lock);
++		e->missed &= ~missed;
++	spin_unlock_bh(&ct->lock);
++}
++#else
+ void nf_ct_deliver_cached_events(struct nf_conn *ct)
+ {
+ 	struct nf_conntrack_ecache *e;
+@@ -226,6 +300,7 @@ void nf_ct_deliver_cached_events(struct
+ 	 */
+ 	__nf_conntrack_eventmask_report(e, events, e->missed, &item);
+ }
++#endif
+ EXPORT_SYMBOL_GPL(nf_ct_deliver_cached_events);
+ 
+ void nf_ct_expect_event_report(enum ip_conntrack_expect_events event,
+@@ -258,20 +333,43 @@ out_unlock:
+ 	rcu_read_unlock();
+ }
+ 
+-void nf_conntrack_register_notifier(struct net *net,
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++int nf_conntrack_register_notifier(struct net *net,
++				   struct notifier_block *nb)
++{
++	return atomic_notifier_chain_register(&net->ct.nf_conntrack_chain, nb);
++}
++#else
++int nf_conntrack_register_notifier(struct net *net,
+ 				    const struct nf_ct_event_notifier *new)
+ {
++	int ret;
+ 	struct nf_ct_event_notifier *notify;
+ 
+ 	mutex_lock(&nf_ct_ecache_mutex);
+ 	notify = rcu_dereference_protected(net->ct.nf_conntrack_event_cb,
+ 					   lockdep_is_held(&nf_ct_ecache_mutex));
+ 	WARN_ON_ONCE(notify);
++	if (notify != NULL) {
++		ret = -EBUSY;
++		goto out_unlock;
++	}
++
+ 	rcu_assign_pointer(net->ct.nf_conntrack_event_cb, new);
+-	mutex_unlock(&nf_ct_ecache_mutex);
++	ret = 0;
++out_unlock:
++ 	mutex_unlock(&nf_ct_ecache_mutex);
++	return ret;
+ }
++#endif
+ EXPORT_SYMBOL_GPL(nf_conntrack_register_notifier);
+ 
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++int nf_conntrack_unregister_notifier(struct net *net, struct notifier_block *nb)
++{
++	return atomic_notifier_chain_unregister(&net->ct.nf_conntrack_chain, nb);
++}
++#else
+ void nf_conntrack_unregister_notifier(struct net *net)
+ {
+ 	mutex_lock(&nf_ct_ecache_mutex);
+@@ -279,6 +377,7 @@ void nf_conntrack_unregister_notifier(st
+ 	mutex_unlock(&nf_ct_ecache_mutex);
+ 	/* synchronize_rcu() is called after netns pre_exit */
+ }
++#endif
+ EXPORT_SYMBOL_GPL(nf_conntrack_unregister_notifier);
+ 
+ void nf_conntrack_ecache_work(struct net *net, enum nf_ct_ecache_state state)
+--- a/net/netfilter/nf_conntrack_netlink.c
++++ b/net/netfilter/nf_conntrack_netlink.c
+@@ -718,12 +718,19 @@ static size_t ctnetlink_nlmsg_size(const
+ }
+ 
+ static int
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++ctnetlink_conntrack_event(struct notifier_block *this, unsigned long events, void *ptr)
++#else
+ ctnetlink_conntrack_event(unsigned int events, const struct nf_ct_event *item)
++#endif
+ {
+ 	const struct nf_conntrack_zone *zone;
+ 	struct net *net;
+ 	struct nlmsghdr *nlh;
+ 	struct nlattr *nest_parms;
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	struct nf_ct_event *item = (struct nf_ct_event *)ptr;
++#endif
+ 	struct nf_conn *ct = item->ct;
+ 	struct sk_buff *skb;
+ 	unsigned int type;
+@@ -3094,6 +3101,7 @@ nla_put_failure:
+ }
+ 
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
++#ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
+ static int
+ ctnetlink_expect_event(unsigned int events, const struct nf_exp_event *item)
+ {
+@@ -3143,6 +3151,7 @@ errout:
+ 	return 0;
+ }
+ #endif
++#endif
+ static int ctnetlink_exp_done(struct netlink_callback *cb)
+ {
+ 	if (cb->args[1])
+@@ -3750,11 +3759,17 @@ static int ctnetlink_stat_exp_cpu(struct
+ }
+ 
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++static struct notifier_block ctnl_notifier = {
++	.notifier_call = ctnetlink_conntrack_event
++};
++#else
+ static struct nf_ct_event_notifier ctnl_notifier = {
+ 	.ct_event = ctnetlink_conntrack_event,
+ 	.exp_event = ctnetlink_expect_event,
+ };
+ #endif
++#endif
+ 
+ static const struct nfnl_callback ctnl_cb[IPCTNL_MSG_MAX] = {
+ 	[IPCTNL_MSG_CT_NEW]	= {
+@@ -3853,8 +3868,12 @@ static int __net_init ctnetlink_net_init
+ static void ctnetlink_net_pre_exit(struct net *net)
+ {
+ #ifdef CONFIG_NF_CONNTRACK_EVENTS
++#ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
++	nf_conntrack_unregister_notifier(net,&ctnl_notifier);
++#else
+ 	nf_conntrack_unregister_notifier(net);
+ #endif
++#endif
+ }
+ 
+ static struct pernet_operations ctnetlink_net_ops = {
